The goal of the project is to estimate hand poses that can be used for hand tracking and gesture recognition using a keypoint-based approach with multi-view RGB images. The input to the system will be multi-view images taken at the same time, either from a stereo camera or two cameras with the same settings. The output will be the hand pose using the 21 keypoints (center of palm and finger joints).

Uses the stereo hand pose dataset created by J. Zhang et al. at https://github.com/zhjwustc/icip17_stereo_hand_pose_dataset.
